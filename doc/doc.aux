\relax 
\citation{keras}
\citation{tensorflow}
\citation{opencv}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Scripts}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Dependency}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Parameters}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Gradient descent}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Discesa del gradiente\relax }}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cc}{{1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces funzione esempio\relax }}{6}}
\newlabel{fig:cc}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces esempio di discesa del gradiente nel caso di un fattore moltiplicatico grande e piccolo.\relax }}{7}}
\newlabel{fig:cc}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}MLPNN: Multi Layer Perceptron Neural Network}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces esempio di MLPNN\relax }}{7}}
\newlabel{fig:cc}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Convolution}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces esempio di convoluzione 2D\relax }}{10}}
\newlabel{fig:cc}{{5}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}CNN: Convolutional Neural Network}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Max Pooling\relax }}{11}}
\newlabel{fig:cc}{{6}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Convolutional Layer\relax }}{12}}
\newlabel{fig:cc}{{7}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces CNN su di una immagine\relax }}{13}}
\newlabel{fig:cc}{{8}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Dropout}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Esempio di Dropout\relax }}{13}}
\newlabel{fig:cc}{{9}{13}}
\citation{cnn}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}RMSprop}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Models}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}built MLPNN}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Modello basso con layer ristretti.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.972 e 0.107.\relax }}{15}}
\newlabel{fig:cc}{{10}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Modello basso con layer ampi.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.982 e 0.067.\relax }}{15}}
\newlabel{fig:cc}{{11}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Modello profondo con layer ristretti.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.970 e 0.123.\relax }}{15}}
\newlabel{fig:cc}{{12}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Modello basso con layer ampi.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.980 e 0.115.\relax }}{15}}
\newlabel{fig:cc}{{13}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Loss del modello basso con layer ristretti.\relax }}{16}}
\newlabel{fig:cc}{{14}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Accuracy del modello basso con layer ristretti.\relax }}{16}}
\newlabel{fig:cc}{{15}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Loss del modello basso con layer ampi.\relax }}{16}}
\newlabel{fig:cc}{{16}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Accuracy del modello basso con layer ampi.\relax }}{16}}
\newlabel{fig:cc}{{17}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Loss del modello profondo con layer ristretti.\relax }}{17}}
\newlabel{fig:cc}{{18}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Accuracy del modello profondo con layer ristretti.\relax }}{17}}
\newlabel{fig:cc}{{19}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Loss del modello profondo con layer ampi.\relax }}{17}}
\newlabel{fig:cc}{{20}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Accuracy del modello profondo con layer ampi.\relax }}{17}}
\newlabel{fig:cc}{{21}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}built CNN}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Modello con kernel e layer ridotti.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.993 e 0.025.\relax }}{18}}
\newlabel{fig:cc}{{22}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Modello con kernel ampi e layer ridotti.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.991 e 0.037.\relax }}{18}}
\newlabel{fig:cc}{{23}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Modello con kernel ristretti e layer ampi.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.987 e 0.051.\relax }}{18}}
\newlabel{fig:cc}{{24}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Modello con kernel e layer ampi.  Il miglior modello ottiene come accuracy e loss sul set di validazione i rispettivi risultati: 0.989 e 0.050.\relax }}{19}}
\newlabel{fig:cc}{{25}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Loss del modello con kernel e layer ridotti.\relax }}{20}}
\newlabel{fig:cc}{{26}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Accuracy del modello con kernel e layer ridotti.\relax }}{20}}
\newlabel{fig:cc}{{27}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Loss del modello con kernel ampi e layer ridotti.\relax }}{20}}
\newlabel{fig:cc}{{28}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Accuracy del modello con kernel ampi e layer ridotti.\relax }}{20}}
\newlabel{fig:cc}{{29}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Loss del modello con kernel ampi e layer ristretti.\relax }}{21}}
\newlabel{fig:cc}{{30}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Accuracy del modello con kernel ampi e layer ristretti.\relax }}{21}}
\newlabel{fig:cc}{{31}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Loss del Modello con kernel e layer ampi.\relax }}{21}}
\newlabel{fig:cc}{{32}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Accuracy del Modello con kernel e layer ampi.\relax }}{21}}
\newlabel{fig:cc}{{33}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Examples}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces 6 riconosciuto come tale.\relax }}{22}}
\newlabel{fig:cc}{{34}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces 5 riconosciuto come tale.\relax }}{22}}
\newlabel{fig:cc}{{35}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces 5 limite riconosciuto come tale.\relax }}{23}}
\newlabel{fig:cc}{{36}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces 6 riconosciuto come 5.\relax }}{23}}
\newlabel{fig:cc}{{37}{23}}
\bibcite{bengio}{1}
\bibcite{gradient}{2}
\bibcite{rmsprop}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces 1 riconosciuto come tale.\relax }}{24}}
\newlabel{fig:cc}{{38}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Improvements}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}References}{24}}
\bibcite{cnn}{4}
\bibcite{keras}{5}
\bibcite{tensorflow}{6}
\bibcite{opencv}{7}
